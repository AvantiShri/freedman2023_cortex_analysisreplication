{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a40c671b",
      "metadata": {
        "id": "a40c671b"
      },
      "outputs": [],
      "source": [
        "#Download the data\n",
        "! curl -O https://raw.githubusercontent.com/AvantiShri/papers_analysisreplication/master/freedman_et_al_2023/their_data/TMS_TRIAL_DATA_2023JUL20.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9d024b5",
      "metadata": {
        "id": "d9d024b5"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "\n",
        "tms_trial_data = pandas.read_csv(\"TMS_TRIAL_DATA_2023JUL20.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a2a6ec2",
      "metadata": {
        "id": "8a2a6ec2"
      },
      "outputs": [],
      "source": [
        "tms_trial_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ca63466",
      "metadata": {
        "id": "3ca63466"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "\n",
        "group_and_condition_to_trialdata = OrderedDict()\n",
        "\n",
        "#gather the data for all of them\n",
        "for group, group_easyname in [(1,\"Rstim_Lfirst\"),\n",
        "                                              (2, \"Rstim_Rfirst\"),\n",
        "                                              (3, \"Lstim_Lfirst\"),\n",
        "                                              (4, \"Lstim_Rfirst\"),\n",
        "                                              (5, \"Sstim_Lfirst\"),\n",
        "                                              (6, \"Sstim_Rfirst\")]:\n",
        "    group_and_condition_to_trialdata[group_easyname] = OrderedDict()\n",
        "    for condition, condition_easyname in [(1, \"expRight\"),\n",
        "                                          (2, \"contRight\"),\n",
        "                                          (3, \"expLeft\"),\n",
        "                                          (4, \"contLeft\")]:\n",
        "        filtered_tms_data = tms_trial_data[(tms_trial_data[\"randomization\"]==group)\n",
        "                                           & (tms_trial_data[\"condition\"]==condition)]\n",
        "        trials_for_all_subjects = [] #gather the trials for all subjects into a list of lists\n",
        "        subject_nums = set(filtered_tms_data[\"id\"])\n",
        "        for subject_num in sorted(subject_nums):\n",
        "            data_for_subject = filtered_tms_data[filtered_tms_data[\"id\"]==subject_num]\n",
        "            #get the reg values, sorted in ascending order by trial number\n",
        "            sorted_reg_values = np.array(data_for_subject[\"reg\"])[np.argsort(data_for_subject[\"trial\"])]\n",
        "            trials_for_all_subjects.append(sorted_reg_values)\n",
        "        trials_for_all_subjects = np.array(trials_for_all_subjects)\n",
        "        group_and_condition_to_trialdata[group_easyname][condition_easyname] = trials_for_all_subjects"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47f76e3c",
      "metadata": {
        "id": "47f76e3c"
      },
      "source": [
        "Plot the trend in the effect for first intention trials with contra-lateral stimulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "011de123",
      "metadata": {
        "scrolled": false,
        "id": "011de123"
      },
      "outputs": [],
      "source": [
        "#plot to make sure\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "lines_to_plot = [\n",
        "    (\"Lstim_Rfirst\", \"Lstim_Lfirst\", \"expRight\", 'red', '-', \"L-stim, right intention\"),\n",
        "    (\"Lstim_Rfirst\", \"Lstim_Lfirst\", \"contRight\", 'red', '--', \"corresponding control\"),\n",
        "    (\"Rstim_Lfirst\", \"Rstim_Rfirst\", \"expLeft\", 'blue', '-', \"R-stim, left intention\"),\n",
        "    (\"Rstim_Lfirst\", \"Rstim_Rfirst\", \"contLeft\", 'blue', '--', \"corresponding control\"),\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "handles = []\n",
        "handle_labels = []\n",
        "for (groupname1, groupname2, conditionname, color, linestyle, label)  in lines_to_plot:\n",
        "    data = np.concatenate([group_and_condition_to_trialdata[groupname1][conditionname],\n",
        "                           group_and_condition_to_trialdata[groupname2][conditionname]], axis=1)\n",
        "    handles.append(\n",
        "         plt.plot(np.cumsum(np.sum(data-100, axis=0))/(np.sqrt(50)*np.sqrt(data.shape[0])),\n",
        "                 color=color,\n",
        "                 linestyle=linestyle)[0])\n",
        "    handle_labels.append(label)\n",
        "plt.title(\"Middle medial frontal lobe rTMS inhibition\")\n",
        "plt.ylabel(\"Cumulative sum of z-scores\\n(z-scores are for the sum of trials over all subjects)\")\n",
        "plt.xlabel(\"Number of seconds\")\n",
        "handles.append(plt.plot([500,500],[-100,100], color=\"purple\", linestyle=\"--\")[0])\n",
        "handle_labels.append(\"Break, change in subject group\")\n",
        "xlim = plt.xlim()\n",
        "plt.plot(xlim, [0,0], color=\"black\")\n",
        "#2 sigma curve:\n",
        "plt.plot(np.arange(data.shape[1]), 2*np.sqrt(1+np.arange(data.shape[1])), linestyle=\"--\", color=\"black\" )\n",
        "plt.plot(np.arange(data.shape[1]), -2*np.sqrt(1+np.arange(data.shape[1])), linestyle=\"--\", color=\"black\" )\n",
        "#3 sigma curve:\n",
        "plt.plot(np.arange(data.shape[1]), 3*np.sqrt(1+np.arange(data.shape[1])), linestyle=\"--\", color=\"black\" )\n",
        "plt.plot(np.arange(data.shape[1]), -3*np.sqrt(1+np.arange(data.shape[1])), linestyle=\"--\", color=\"black\" )\n",
        "plt.ylim(-100,100)\n",
        "plt.legend(handles=handles, labels=handle_labels, loc=3)\n",
        "plt.savefig('contra_stim_intention_trials.eps', format='eps')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visually, after the break, it seems that the L-stim, right intention group of participants is having an effect in the opposite direction. To build our intuition for statistical significance, let's compute the z-score for just that trial group, keeping in mind that any resulting z-score (if formally reported) would need to be subject to multiple hypothesis correction over all possible groups, trials and directions, since we have no pre-defined reason to suspect that this trial for this group should move in the negative direction"
      ],
      "metadata": {
        "id": "HF78I1XAgNt8"
      },
      "id": "HF78I1XAgNt8"
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "\n",
        "data = group_and_condition_to_trialdata[\"Lstim_Lfirst\"][\"expRight\"]\n",
        "z_score = np.sum(data-100)/np.sqrt(50*data.shape[0]*data.shape[1])\n",
        "print(\"z score:\", z_score)\n",
        "print(\"percentile\", scipy.stats.norm.cdf(z_score)) #this would not be significant after multiple hypothesis correction over all groups and directions, which would be appropriate since this is a post-hoc analysis"
      ],
      "metadata": {
        "id": "UXM_0FtidcP2"
      },
      "id": "UXM_0FtidcP2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6a947ff1",
      "metadata": {
        "id": "6a947ff1"
      },
      "source": [
        "Check device variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0a60203",
      "metadata": {
        "id": "e0a60203"
      },
      "outputs": [],
      "source": [
        "#verify that the device variance is near the theoretical expectation of 50\n",
        "print(np.var(group_and_condition_to_trialdata[\"Lstim_Rfirst\"][\"contRight\"]))\n",
        "print(np.mean(group_and_condition_to_trialdata[\"Lstim_Rfirst\"][\"contRight\"]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check for all the controls\n",
        "all_controls = np.concatenate([\n",
        "    group_and_condition_to_trialdata[\"Lstim_Rfirst\"][\"contRight\"],\n",
        "    group_and_condition_to_trialdata[\"Lstim_Rfirst\"][\"contLeft\"],\n",
        "    group_and_condition_to_trialdata[\"Lstim_Lfirst\"][\"contRight\"],\n",
        "    group_and_condition_to_trialdata[\"Lstim_Lfirst\"][\"contLeft\"],\n",
        "    group_and_condition_to_trialdata[\"Rstim_Rfirst\"][\"contRight\"],\n",
        "    group_and_condition_to_trialdata[\"Rstim_Rfirst\"][\"contLeft\"],\n",
        "    group_and_condition_to_trialdata[\"Rstim_Lfirst\"][\"contRight\"],\n",
        "    group_and_condition_to_trialdata[\"Rstim_Lfirst\"][\"contLeft\"],\n",
        "    group_and_condition_to_trialdata[\"Sstim_Rfirst\"][\"contRight\"],\n",
        "    group_and_condition_to_trialdata[\"Sstim_Rfirst\"][\"contLeft\"],\n",
        "    group_and_condition_to_trialdata[\"Sstim_Lfirst\"][\"contRight\"],\n",
        "    group_and_condition_to_trialdata[\"Sstim_Lfirst\"][\"contLeft\"],\n",
        "], axis=0)\n",
        "print(all_controls.shape, all_controls.ravel().shape)\n",
        "empirical_var = np.var(all_controls, ddof=1) #ddof=1 makes it an unbiased estimate of the variance i.e. sample variance\n",
        "empirical_mean = np.mean(all_controls)\n",
        "print(empirical_var, empirical_mean)"
      ],
      "metadata": {
        "id": "uKwOPIzYo6Qu"
      },
      "id": "uKwOPIzYo6Qu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cb953cf2",
      "metadata": {
        "id": "cb953cf2"
      },
      "source": [
        "Compute the standard error for the mean and variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4973a4c6",
      "metadata": {
        "scrolled": false,
        "id": "4973a4c6"
      },
      "outputs": [],
      "source": [
        "import scipy.stats\n",
        "\n",
        "#standard error of mean\n",
        "print(\"standard error of sample mean\", scipy.stats.sem(all_controls.ravel())) #this is equivalent to np.std(all_controls.ravel(), ddof=1)/np.sqrt(108000)\n",
        "#Standard error of variance - https://stats.stackexchange.com/questions/156518/what-is-the-standard-error-of-the-sample-standard-deviation\n",
        "N = 108000\n",
        "mu4 = np.mean(np.power(all_controls - np.mean(all_controls), 4))\n",
        "print(\"standard error of sample variance\", np.sqrt( ( mu4 - ((N-3)/(N-1))*(np.std(all_controls)**4) )/N ))\n",
        "#As a sanity check, can compare to the standard error of the variance for a normal distribution\n",
        "# (which the binomial distribution approximates by the central limit theorem)\n",
        "print(\"standard error of sample variance applying CLT:\", np.sqrt(2*(np.std(all_controls)**4)/(N-1)))\n",
        "#As a further check, let's compare to the asymptotic standard error expected for a binomial distribution:\n",
        "#Asymptotic standard error of variance for binomial distribution: https://stats.stackexchange.com/questions/105337/asymptotic-distribution-of-sample-variance-of-non-normal-sample/105338#105338\n",
        "# Needs the fourth central moment of the binomial distribution: https://math.stackexchange.com/questions/142437/how-to-calculate-the-4th-central-moment-of-binomial-distribution\n",
        "fourth_central_moment = (200*(0.5**5) + 3*200*199*(0.5**4))\n",
        "print(\"asymptotic standard error of variance for binomial distribution:\", np.sqrt((fourth_central_moment - (50**2))/N))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have reason to suspect a declining effect, a monotonically decreasing weighting function is justified. We can compute a test statistic computes the p-value at each possible cutoff for the number of seconds to include, and compares that to the minimum p-value obtained over 10000 simulated trials (where the trial sum at each second is drawn from a binomial distribution). This in effect does muliple hypothesis correction over all possible monotonically decreasing weighting functions."
      ],
      "metadata": {
        "id": "8OVd1cidGjJM"
      },
      "id": "8OVd1cidGjJM"
    },
    {
      "cell_type": "code",
      "source": [
        "true_data = np.concatenate([\n",
        "    group_and_condition_to_trialdata[\"Lstim_Rfirst\"][\"expRight\"],\n",
        "    group_and_condition_to_trialdata[\"Lstim_Lfirst\"][\"expRight\"]], axis=1)\n",
        "\n",
        "NUM_SIM_TRIALS = 10000\n",
        "sim_data = np.random.RandomState(1234).binomial(n=200, p=0.5,\n",
        "                  size=(NUM_SIM_TRIALS, true_data.shape[0], true_data.shape[1]))"
      ],
      "metadata": {
        "id": "6RIp3on3GjpV"
      },
      "id": "6RIp3on3GjpV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import Patch\n",
        "\n",
        "def compute_cumsum_zscores(data, mean=100, var=50):#, do_plotting=False, plot_title=None, alpha=1.0, color=\"blue\"):\n",
        "  #Our goal in this function is to compute the statistical significance that would\n",
        "  # be obtained if we had freedom to choose the number of seconds to include\n",
        "  # (there is one 200-bit RNG sample per subject and second)\n",
        "  #The data has shape (num_subjects, num_seconds)\n",
        "  #first, we convert the individual 200-bit RNG samples to z-scores by subtracting the\n",
        "  # mean (100) and dividing by the standard deviation (sqrt(50)) for a\n",
        "  # binomial distribution with n=200 and p=0.5\n",
        "  #If dealing with real data, we can also use the empirical mean and standard deviation\n",
        "  # if these are more conservative (these are provided as function arguments)\n",
        "  #then we take the sum over all subjects per second, and convert that to\n",
        "  # a z-score for the second by dividing by sqrt of the number of subjects\n",
        "  persecond_zscores = np.sum((data - mean)/np.sqrt(var), axis=0)/np.sqrt(data.shape[0])\n",
        "  #Now we take the cumulative sum of per-second z-scores up to any given number\n",
        "  # of seconds, and convert THAT to a z-score\n",
        "  #We do this by dividing the cumulative sum up to the ith second by sqrt(i)\n",
        "  #Note that np.arange(...) starts at 0, so we have to add 1\n",
        "  cumsum_zscores = np.cumsum(persecond_zscores)/np.sqrt(np.arange(len(persecond_zscores))+1)\n",
        "\n",
        "  return cumsum_zscores\n",
        "\n",
        "sim_cumsum_zscores = np.array([compute_cumsum_zscores(data=x) for x in sim_data])\n",
        "sim_max_zs = np.max(sim_cumsum_zscores, axis=1)\n",
        "\n",
        "true_data_cumsum_zscores = compute_cumsum_zscores(data=true_data);#, mean=empirical_mean, var=empirical_var)\n",
        "true_data_max_z = np.max(true_data_cumsum_zscores)\n",
        "true_data_max_z_second = np.argmax(true_data_cumsum_zscores) + 1\n",
        "\n",
        "#plotting\n",
        "for i in range(0,sim_data.shape[0],200):\n",
        "  plt.plot(np.arange(len(sim_cumsum_zscores[i]))+1, sim_cumsum_zscores[i], color=\"orange\")\n",
        "handle = plt.plot(np.arange(len(true_data_cumsum_zscores))+1, true_data_cumsum_zscores, color=\"blue\")[0]\n",
        "plt.legend(handles=[handle, Patch(facecolor=\"orange\", alpha=1)], labels=[\"True data\", \"Sim data\"], loc=0)\n",
        "plt.xlabel(\"Number of seconds\")\n",
        "plt.ylabel(\"Z-score if stopping at number of seconds on x-axis\")\n",
        "plt.title(\"L-stim, right intention\")\n",
        "plt.plot([0,true_data.shape[1]], [0,0], color=\"black\")\n",
        "plt.plot([0,true_data.shape[1]], [2,2], color=\"black\", linestyle=\"--\")\n",
        "plt.plot([0,true_data.shape[1]], [3,3], color=\"black\", linestyle=\"--\")\n",
        "\n",
        "print(\"Maximum 'posthoc' z-score for true data:\", true_data_max_z,\n",
        "      \"- attained at second number \"+str(true_data_max_z_second))\n",
        "\n",
        "plt.savefig('zscore_if_stopping_at_each_second.eps', format='eps')"
      ],
      "metadata": {
        "id": "MzhnN48bKxK2"
      },
      "id": "MzhnN48bKxK2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(sim_max_zs, bins=50, color=\"orange\")\n",
        "plt.arrow(true_data_max_z, 100, 0, -100, color=\"blue\", head_length=10, length_includes_head=True, width=0.05)\n",
        "plt.xlabel(\"Max cumsum z\")\n",
        "plt.ylabel(\"Number of simulated trials\")\n",
        "plt.legend(handles=[Patch(color='blue', label='L-stim, right intention data'),\n",
        "                    Patch(color='orange', label='Simulated data')],\n",
        "           loc=\"upper right\")\n",
        "plt.title(str(NUM_SIM_TRIALS)+\" Monte Carlo Simulations\")\n",
        "plt.savefig('histogram_of_max_z_score.eps', format='eps')\n",
        "\n",
        "true_rank = np.sum(true_data_max_z > sim_max_zs)\n",
        "print(\"Percentile of true relative to simualted: \", true_rank/NUM_SIM_TRIALS)\n",
        "#Note: the +1 correction in the numerator and denominator is based on https://pubmed.ncbi.nlm.nih.gov/21044043/\n",
        "print(\"P value of true relative to simulated:\", (1+NUM_SIM_TRIALS-true_rank)/(1+NUM_SIM_TRIALS) )"
      ],
      "metadata": {
        "id": "__WD5JCPido-"
      },
      "id": "__WD5JCPido-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ebe716aa",
      "metadata": {
        "id": "ebe716aa"
      },
      "source": [
        "Plot the distribution of the effect for Lstim_Rfirst expRight for individual subjects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c4e5d04",
      "metadata": {
        "id": "1c4e5d04"
      },
      "outputs": [],
      "source": [
        "data = group_and_condition_to_trialdata[\"Lstim_Rfirst\"][\"expRight\"]\n",
        "\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "\n",
        "for i in range(data.shape[0]):\n",
        "    plt.plot(np.cumsum(data[i,:]-100)/(np.sqrt(50)))\n",
        "xlim = plt.xlim()\n",
        "plt.plot(xlim, [0,0], color=\"black\")\n",
        "#2 sigma curve:\n",
        "plt.plot(np.arange(data.shape[1]), 2*np.sqrt(1+np.arange(data.shape[1])), linestyle=\"--\", color=\"black\" )\n",
        "plt.plot(np.arange(data.shape[1]), -2*np.sqrt(1+np.arange(data.shape[1])), linestyle=\"--\", color=\"black\" )\n",
        "#3 sigma curve:\n",
        "plt.plot(np.arange(data.shape[1]), 3*np.sqrt(1+np.arange(data.shape[1])), linestyle=\"--\", color=\"black\" )\n",
        "plt.plot(np.arange(data.shape[1]), -3*np.sqrt(1+np.arange(data.shape[1])), linestyle=\"--\", color=\"black\" )\n",
        "plt.title(\"Individual trials for L-stim, right intention when done first\")\n",
        "plt.ylabel(\"Cumulative sum of z-scores\\n(z-scores for individual trials)\")\n",
        "plt.xlabel(\"Number of seconds\")\n",
        "\n",
        "plt.savefig('Lstim_Rfirst_expRight_individual.eps', format='eps')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some other values"
      ],
      "metadata": {
        "id": "xR62EoK6J-1y"
      },
      "id": "xR62EoK6J-1y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56b47d3c",
      "metadata": {
        "id": "56b47d3c"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "\n",
        "print(\"95th percentile is sigma=\",scipy.stats.norm.ppf(0.95))\n",
        "print(\"2 sigma is a percentile of\",scipy.stats.norm.cdf(2))\n",
        "print(\"3 sigma is a percentile of\",scipy.stats.norm.cdf(3))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}